{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Load data fromkeras.datasets and perform following computational analysis:- [CO3]**\n",
        "**(a) Preprocessing of the Data**\n",
        "\n",
        "**(b) Divide data into training and testing data set**\n",
        "\n",
        "**(c) Build the Gated Recurrent Units (GRU) Model**\n",
        "\n",
        "**(d) Training the GRU Model**\n",
        "\n",
        "**(e) Text Generation Using the Trained Model**\n",
        "\n",
        "**(f)  Evaluate Model’s accuracy**"
      ],
      "metadata": {
        "id": "mRwkwfmKwOBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=20000)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "maxlen = 200\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Build the Gated Recurrent Units (GRU) Model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=20000, output_dim=128))\n",
        "model.add(layers.GRU(128))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Training the GRU Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate Model's accuracy\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V6pO6zBru_qv",
        "outputId": "4c9432b5-27f9-4c48-aa50-343b8a8e9463"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 296ms/step - accuracy: 0.7033 - loss: 0.5365 - val_accuracy: 0.8728 - val_loss: 0.3190\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 297ms/step - accuracy: 0.9173 - loss: 0.2156 - val_accuracy: 0.8868 - val_loss: 0.2867\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 301ms/step - accuracy: 0.9660 - loss: 0.0989 - val_accuracy: 0.8872 - val_loss: 0.3278\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 301ms/step - accuracy: 0.9865 - loss: 0.0416 - val_accuracy: 0.8768 - val_loss: 0.4509\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 299ms/step - accuracy: 0.9943 - loss: 0.0188 - val_accuracy: 0.8712 - val_loss: 0.5190\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 63ms/step - accuracy: 0.8556 - loss: 0.5771\n",
            "Test accuracy: 0.8567600250244141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Compare accuracy of Long sort term memory and Gated recurrent Unit models for text generation using data from tensorflow.keras.datasets. [CO3]**"
      ],
      "metadata": {
        "id": "zgSBKqOdxxJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "max_len = 200\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(10000, 128))\n",
        "lstm_model.add(LSTM(128))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the LSTM model\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the GRU model\n",
        "gru_model = Sequential()\n",
        "gru_model.add(Embedding(10000, 128))\n",
        "gru_model.add(GRU(128))\n",
        "gru_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the GRU model\n",
        "gru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Train the GRU model\n",
        "gru_model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the models\n",
        "lstm_loss, lstm_accuracy = lstm_model.evaluate(x_test, y_test)\n",
        "gru_loss, gru_accuracy = gru_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('LSTM Accuracy:', lstm_accuracy)\n",
        "print('GRU Accuracy:', gru_accuracy)\n",
        "\n",
        "# Compare the accuracy of the models\n",
        "if lstm_accuracy > gru_accuracy:\n",
        "  print('LSTM model has higher accuracy.')\n",
        "elif gru_accuracy > lstm_accuracy:\n",
        "  print('GRU model has higher accuracy.')\n",
        "else:\n",
        "  print('Both models have similar accuracy.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AgsG_pXAnYDl",
        "outputId": "b483209c-7832-41a6-daca-1b689b2c222f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 505ms/step - accuracy: 0.6755 - loss: 0.5703 - val_accuracy: 0.7958 - val_loss: 0.4429\n",
            "Epoch 2/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 507ms/step - accuracy: 0.8781 - loss: 0.3036 - val_accuracy: 0.8632 - val_loss: 0.3316\n",
            "Epoch 3/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 503ms/step - accuracy: 0.9219 - loss: 0.2052 - val_accuracy: 0.8708 - val_loss: 0.3259\n",
            "Epoch 1/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 537ms/step - accuracy: 0.6337 - loss: 0.6169 - val_accuracy: 0.8298 - val_loss: 0.3920\n",
            "Epoch 2/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 577ms/step - accuracy: 0.8878 - loss: 0.2817 - val_accuracy: 0.8648 - val_loss: 0.3341\n",
            "Epoch 3/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 536ms/step - accuracy: 0.9251 - loss: 0.1980 - val_accuracy: 0.8828 - val_loss: 0.3014\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 112ms/step - accuracy: 0.8624 - loss: 0.3463\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 60ms/step - accuracy: 0.8730 - loss: 0.3236\n",
            "LSTM Accuracy: 0.8644800186157227\n",
            "GRU Accuracy: 0.8750399947166443\n",
            "GRU model has higher accuracy.\n"
          ]
        }
      ]
    }
  ]
}